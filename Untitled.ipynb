{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Yes\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1679808491,\n",
      "  \"id\": \"chatcmpl-6yDDHMHZGaYQ8Vn6HW8VRxM2Rl5js\",\n",
      "  \"model\": \"gpt-4-0314\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1,\n",
      "    \"prompt_tokens\": 56,\n",
      "    \"total_tokens\": 57\n",
      "  }\n",
      "}\n",
      "Yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "OPENAI_API_KEY = \"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\"\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "engine = \"gpt-4\"\n",
    "conversation_history = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, # you can change this to 'You are an expert programmer that only outputs code\" etc\n",
    "        ]\n",
    "question = \"What is the sum of fractions 1/2 and 1/3.\"\n",
    "answer = \"5/6\"\n",
    "prompt = \"Question:\" + question + \"\\n\" + \"Answer:\" + answer + \"\\n\" \"Is the above answer to the question correct. Give a yes or no answer\"\n",
    "conversation_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",  # Replace with the appropriate model name for GPT-4\n",
    "    messages=conversation_history,\n",
    "    # max_tokens=8192,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    ")\n",
    "print(response)\n",
    "ai_message = response['choices'][0]['message']['content'].strip()\n",
    "print(ai_message)\n",
    "conversation_history.append({\"role\": \"assistant\", \"content\": ai_message})\n",
    "# headers = {\n",
    "#     \"Content-Type\": \"application/json\",\n",
    "#     \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "# }\n",
    "# data = {\n",
    "#     \"prompt\": prompt,\n",
    "#     \"max_tokens\": 10,\n",
    "#     \"n\": 1,\n",
    "#     \"stop\": None,\n",
    "#     \"temperature\": 0.5,\n",
    "# }\n",
    "\n",
    "# try:\n",
    "#     response = requests.post(OPENAI_API_URL, headers=headers, json=data)\n",
    "#     response.raise_for_status()\n",
    "#     result = response.json()\n",
    "#     answer = result['choices'][0]['text'].strip().lower()\n",
    "\n",
    "#     if answer not in [\"yes\", \"no\"]:\n",
    "#         return {\"error\": \"Invalid response from the GPT-4 model.\"}\n",
    "\n",
    "#     return {\"answer\": answer}\n",
    "\n",
    "# except requests.exceptions.RequestException as e:\n",
    "#     return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "\n",
    "# def check_answer():\n",
    "#     data = request.get_json()\n",
    "#     answer = data.get('prompt')\n",
    "#     context = data.get('context')\n",
    "\n",
    "def check_answer(question, answer):\n",
    "#     prompt = \"Suppose a question a student is trying to answer is the following: '\" + question + \"'\\n\" + \". The student's answer is: '\" + answer + \"'\\n Is the above answer to the question correct \\n Think really hard before you answer\"#. Give a yes or no answer\"\n",
    "#     context = [item.copy() for item in conversation_history]\n",
    "#     if not prompt:\n",
    "#         return jsonify({'error': 'Invalid input. Please provide a prompt.'}), 400\n",
    "#     if not context:\n",
    "#         return jsonify({'error': 'Invalid input. Please provide a context.'}), 400\n",
    "\n",
    "#     response = call_openai_api(prompt, context)\n",
    "#     prompt = \"Answer in one word is the students answer 'correct' or 'incorrect'?\"\n",
    "#     response = call_openai_api(prompt, response[\"context\"])\n",
    "#     answer = response[\"ai_message\"].lower()\n",
    "# #     if answer not in [\"yes\", \"no\"]:\n",
    "# #         return {\"error\": \"Invalid response from the GPT-4 model.\"}\n",
    "\n",
    "#     if 'error' in response:\n",
    "#         return jsonify(response), 400\n",
    "    prompt = \"Suppose a question a student is trying to answer is the following: '\" + question + \"'\\n\" + \". The student's answer is: '\" + answer + \"'\\n Is the above answer to the question correct \\n Think really hard before you answer\"\n",
    "    context = [item.copy() for item in conversation_history]\n",
    "    if not prompt:\n",
    "        return jsonify({'error': 'Invalid input. Please provide a prompt.'}), 400\n",
    "    if not context:\n",
    "        return jsonify({'error': 'Invalid input. Please provide a context.'}), 400\n",
    "    context.append({\"role\": \"system\", \"content\": \"You can only say correct or incorrect, exclusively.\"})\n",
    "    response = call_openai_api(prompt, context)\n",
    "    # prompt = \"Answer in one word is the students answer 'correct' or 'incorrect'?\"\n",
    "    # response = call_openai_api(prompt, response[\"context\"])\n",
    "    answer = response[\"ai_message\"].lower()\n",
    "    if answer not in [\"correct\", \"incorrect\"]:\n",
    "        return {\"error\": \"Invalid response from the GPT-4 model.\"}\n",
    "\n",
    "    if 'error' in response:\n",
    "        return jsonify(response), 400\n",
    "\n",
    "    print(answer)\n",
    "    return jsonify({\"answer\": answer}), 200\n",
    "\n",
    "def call_openai_api(prompt, context):\n",
    "    try:\n",
    "        context.append({\"role\": \"user\", \"content\": prompt})\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",  # Replace with the appropriate model name for GPT-4\n",
    "            messages=context,\n",
    "            # max_tokens=8192,\n",
    "            n=1,\n",
    "            stop=None,\n",
    "            temperature=0.01,\n",
    "        )\n",
    "        print(response)\n",
    "        ai_message = response['choices'][0]['message']['content'].strip()\n",
    "        context.append({\"role\": \"assistant\", \"content\": ai_message})\n",
    "\n",
    "        return {\"ai_message\": ai_message, \"context\": context}\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def generate_question(context):\n",
    "#     data = request.get_json()\n",
    "#     context = data.get('context')\n",
    "    system_content = \"\"\"\n",
    "        Given that the student has not answered the question correctly, create a follow-up question that will aid the student in achieving the final objective that was stated earlier in the context. Ask the student a question to probe if they are confused with this follow-up response. Do not give the student the final answer either; only guide them.\n",
    "        Start with the sentence, 'Here is a follow-up question to help you reach the next step: '. Afterwards, generate a follow-up question after the colon.\n",
    "    \"\"\"\n",
    "    context.append({\"role\": \"system\", \"content\": {system_content}})\n",
    "    ai_contents = call_openai_api(\"\", context) # ai_message, context\n",
    "    \n",
    "    return ai_contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"content\": \"Correct\",\n",
      "        \"role\": \"assistant\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1679819054,\n",
      "  \"id\": \"chatcmpl-6yFxe6csj1zZmAYhc1SSpKApDp388\",\n",
      "  \"model\": \"gpt-4-0314\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 1,\n",
      "    \"prompt_tokens\": 91,\n",
      "    \"total_tokens\": 92\n",
      "  }\n",
      "}\n",
      "correct\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Working outside of application context.\n\nThis typically means that you attempted to use functionality that needed\nto interface with the current application object in some way. To solve\nthis, set up an application context with app.app_context().  See the\ndocumentation for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-cca90acbc66a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Question:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Answer:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m\"Is the above answer to the question correct. Give a yes or no answer\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# conversation_history.append({\"role\": \"user\", \"content\": prompt})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcheck_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-59-bdae3eb0d812>\u001b[0m in \u001b[0;36mcheck_answer\u001b[0;34m(question, answer)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjsonify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"answer\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcall_openai_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/flask/json/__init__.py\u001b[0m in \u001b[0;36mjsonify\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0mseparators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcurrent_app\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"JSONIFY_PRETTYPRINT_REGULAR\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcurrent_app\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0mindent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mseparators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\": \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/werkzeug/local.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__members__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_current_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_current_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/werkzeug/local.py\u001b[0m in \u001b[0;36m_get_current_object\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \"\"\"\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__release_local__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/flask/globals.py\u001b[0m in \u001b[0;36m_find_app\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_app_ctx_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_app_ctx_err_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Working outside of application context.\n\nThis typically means that you attempted to use functionality that needed\nto interface with the current application object in some way. To solve\nthis, set up an application context with app.app_context().  See the\ndocumentation for more information."
     ]
    }
   ],
   "source": [
    "conversation_history = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, # you can change this to 'You are an expert programmer that only outputs code\" etc\n",
    "        ]\n",
    "question = \"What is the sum of fractions (3/4) and (8/12).\"\n",
    "answer = \"19/12\"\n",
    "prompt = \"Question:\" + question + \"\\n\" + \"Answer:\" + answer + \"\\n\" \"Is the above answer to the question correct. Give a yes or no answer\"\n",
    "# conversation_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "check_answer(question,answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-0.27.2-py3-none-any.whl (70 kB)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /anaconda3/lib/python3.7/site-packages (from openai) (4.42.1)\n",
      "Requirement already satisfied, skipping upgrade: requests>=2.20 in /anaconda3/lib/python3.7/site-packages (from openai) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions; python_version < \"3.8\" in /anaconda3/lib/python3.7/site-packages (from openai) (3.10.0.0)\n",
      "Requirement already satisfied, skipping upgrade: aiohttp in /anaconda3/lib/python3.7/site-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests>=2.20->openai) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests>=2.20->openai) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda3/lib/python3.7/site-packages (from requests>=2.20->openai) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests>=2.20->openai) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: attrs>=17.3.0 in /anaconda3/lib/python3.7/site-packages (from aiohttp->openai) (19.2.0)\n",
      "Requirement already satisfied, skipping upgrade: multidict<7.0,>=4.5 in /anaconda3/lib/python3.7/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied, skipping upgrade: frozenlist>=1.1.1 in /anaconda3/lib/python3.7/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied, skipping upgrade: asynctest==0.13.0; python_version < \"3.8\" in /anaconda3/lib/python3.7/site-packages (from aiohttp->openai) (0.13.0)\n",
      "Requirement already satisfied, skipping upgrade: aiosignal>=1.1.2 in /anaconda3/lib/python3.7/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: yarl<2.0,>=1.0 in /anaconda3/lib/python3.7/site-packages (from aiohttp->openai) (1.8.2)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer<3.0,>=2.0 in /anaconda3/lib/python3.7/site-packages (from aiohttp->openai) (2.1.1)\n",
      "Requirement already satisfied, skipping upgrade: async-timeout<5.0,>=4.0.0a3 in /anaconda3/lib/python3.7/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.27.0\n",
      "    Uninstalling openai-0.27.0:\n",
      "      Successfully uninstalled openai-0.27.0\n",
      "Successfully installed openai-0.27.2\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
